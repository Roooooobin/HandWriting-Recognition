# 程序文档说明

程序主要分为处理数据集、建立模型、训练模型并测试、运行并预测结果这四个模块，下面依次介绍

## 数据集描述

本程序做到了识别数字和字母，他们的源文件都是二进制文件，需要进行一系列处理之后转换为标准的numpy数组之后才能进行后续的操作

#### 数字

数字的数据来自于[MNIST数据集](http://yann.lecun.com/exdb/mnist/)，训练集有60000个，测试集有10000个，源文件保存在**MNIST_number**文件夹下，是二进制文件，通过一系列数据处理之后输入部分转换为标准的28\*28的numpy数组，后续根据具体的模型还要再调整

标签部分为0-9分别表示数字0-9

#### 字母

字母的数据来自于[EMNIST数据集](https://www.nist.gov/node/1298471/emnist-dataset)，训练集有128000个，测试集有20800个，源文件保存在**EMNIST_letter**文件夹下，同样是二进制文件，但是原图片不是正常“姿势”，所以需要先镜像翻转+顺时针旋转90°变为正常的再在后续进行训练

字母数据集不区分大小写，标签为1-26，0不表示任何字母，即A/a都对应1

## 算法及其模型简述

**这里仅是对工程中所使用的算法的简述**，由于存在外部的手写图片作为输入数据，所以在数据上会有调整，而且存在多种算法的选择，预测部分会有一个函数封装好方便调用不同的算法，后面会详细提到

### 卷积神经网络（CNN）

调用keras框架，构建卷积神经网络模型

#### 预处理输入数据

keras框架的CNN模型的输入格式为四维（图片数量，图片高度，图片宽度，图像通道数），本实验是灰度图，通道数为1，而上述所说的标准数据集经过第一步处理之后的是28*28的numpy数组，需要使用$np.expand\_dims$扩展到四维

#### 建立模型

定义一个Sequential模型，中间添加了三层Conv2D卷积层，激励函数为relu，输出层（字母数据集输出维度：27，数字数据集输出维度：10）的激励函数为softmax，然后编译，损失函数为"categorical_crossentropy"，优化器为"rmsprop"

#### 训练模型

使用训练集训练模型，调用fit函数，参数设置为跑5轮epoch，一个batch有512个数据，将其中百分之十的训练数据作为测试集

#### 测试准确率

让模型在测试集上跑，得到测试数据上的正确率，在**数字**测试集上的准确率达到了**99.23%**，在**字母**测试集上的准确率达到**82.90%**

#### 预测

直接调用.predict函数即可

### 神经网络

调用keras框架，建立一般的多层感知机的神经网络

#### 预处理输入数据

keras框架的NN模型的输入格式为二维（图片数量，“图片总大小”），其中图片总大小是输入图片高度\*宽度，即28\*28，所以经过处理后的标准数据集还需要经过一次$.reshape(len(data), 28*28)$，从原三维压为二维

#### 建立模型

定义一个Sequential模型，中间添加了中间层，每层有512个神经元，激励函数为'relu'，输出层（字母数据集输出维度：27，数字数据集输出维度：10）的激励函数为softmax，各层均为全连接，然后编译，损失函数为"mse"（均方误差），优化器为"adam"

#### 训练模型

使用训练集训练模型，调用fit函数，参数设置为跑5轮epoch，一个batch有512个数据，将其中百分之十的训练数据作为测试集

#### 测试准确率

让模型在测试集上跑，得到测试数据上的正确率，在**数字**测试集上的准确率达到了**97.26%**，在**字母**测试集上的准确率达到**91.57%**

#### 预测

直接调用.predict函数即可

### SVM和KNN

调用sklearn框架中的分类器SVM和KNN，建立模型和训练、测试都很简单不再赘述，最后SVM在**数字**测试集上的准确率为**94.04%**，KNN在**数字**测试集上的准确率为**97.05%**

## 重要模块(.py文件)说明

由于本工程存在各种算法（CNN、NN、SVM、KNN）以及不同的识别目标（数字、字母、数字+字母），所以将各种方法的模型的建立、训练、测试都封装在一个py文件中，下面介绍比较重要的若干函数py文件，基本按照的是整个工程的顺序

### utils.py

由于工程存在一些在不同模块都会用到的函数，所以将这些工具型函数整合在utils.py文件下，这样可以方便各模块调用，比如反相灰度图，反相二值化，寻找边缘，转换为MNIST格式，显示结果等函数

### load_data.py

其中包括一般神经网络和卷积神经网络的数据处理，SVM和KNN分类方法的输入数据可以直接使用一般神经网络的输入数据，但是标签有所不同，两种神经网络的标签格式为经过$to\_categorical$的$one-hot$向量（如标签1在数字识别中表示为[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]），而分类器的标签就是一个单独的数字，所以在标签格式上需要特殊处理，具体格式在算法及模型简述中已经提到

对于数字和字母同时识别，需要对数据集做一个合并操作，数据部分可以直接用append加在后面，但是标签需要再处理，数字数据集的标签为0-9单个数字的one-hot向量表示，字母数据集的标签为1-26单个数字的one-hot向量表示（0-26，0不表示任何字母，共27维），那么我处理的方式是对数字数据集的标签向量后加上27个0，字母数据集的标签向量前加10个零，都扩展为37维的one-hot向量，0-9表示数字0-9，11-36表示字母a(A)-z(Z)

### build_model.py

其中包括了卷积神经网络和一般的多层感知机神经网络（记作"baseline"）的模型建立，由于分类器的模型建立就一句话，所以没有再写到该文件中

### fit_model.py

包括了神经网络模型的训练，分类器的建立和训练

因为训练往往时间比较长，所以将训练好的模型保存在models文件下，以后每次运行的时候直接载入模型

### predicting.py

因为神经网络与分类器的框架使用不同且数据输出的格式有异，故将各个算法的预测整合在该py文件下，对predict函数增加一个method参数来通过该参数选择使用的算法，最后函数返回预测结果

### main.py

工程的主函数部分（非在界面运行）

首先训练所有的模型，模型训练一般需要一定的时间而且往往不短，那么需要预处理将模型建立、训练好并且保存，此后每次运行都只需要导入事先保存好的模型

然后设置图片路径，通过设置算法和识别对象选择模型路径，然后调用run函数

#### run

run函数就是运行函数，接受了图片路径，使用opencv的imread函数导入图片，然后根据图片格式转换为标准的MNIST(28\*28)，然后调用predicting.py中的predict函数，得到预测结果后显示带有标注的图片结果以及返回文本结果

main函数中获取run函数返回的预测结果，打印预测结果，完成手写识别

## 文件存储说明

### models

**文件夹models保存了实验中训练好的模型**

#### 卷积神经网络

卷积神经网络的模型，又分为识别数字(**model_convolution_number.h5**)、字母(**model_convolution_letter.h5**)的两个模型，通过keras框架下的.save函数以及h5py包依赖存储为.h5文件，使用则load_model(path)

#### 一般神经网络

一般的多层感知机的神经网络模型，在本实验中称为"baseline"，仅仅表示一个名称，有“基准”/“对照组”之意，分别为识别数字(**model_baseline_number.h5**)、字母(**model_baseline_letter.h5**)、数字字母合并(**model_baseline_combined.h5**)

#### 分类器（SVM、KNN）

使用sklearn框架的SVM和KNN分类器并用joblib.dump保存模型为.m文件，使用时调用joblib.load(path)引入模型，**KNN(n=3)_letter.m**、**KNN(n=3)_number.m**、**SVM(C=1.0)_letter.m**、**SVM(C=1.0)_number.m**

### images

images文件下存放了测试使用的图片

### EMNIST_letter和MNIST_number

EMNIST_letter和MNIST_number分别存放字母数据集和数字数据集的源文件（处理前的二进制文件）

## 使用说明

![1559279194330](../HandWriting%20Recognition/%E7%A8%8B%E5%BA%8F%E6%96%87%E6%A1%A3%E8%AF%B4%E6%98%8E.assets/1559279194330.png)

### 使用说明

在手写板上写一段数字/字母或者直接上传图片，点击识别之后，首先将手写的或者上传的图片保存到指定路径，选择不同的算法和作用对象，主模块中的run函数接收该图片的路径参数，接受选择的算法和作用对象参数，返回预测结果和显示标有预测结果的图片

